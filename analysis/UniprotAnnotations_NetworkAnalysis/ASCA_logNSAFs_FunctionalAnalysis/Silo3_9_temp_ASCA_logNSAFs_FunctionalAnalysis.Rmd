---
title: "Silo3_9_ASCA_logNSAFs_FunctionalAnalysis"
author: "Shelly Trigg"
date: "9/14/2019"
output: html_document
---

**load libraries**
```{r}
#load libraries
library(plyr)
library(tidyr)
library(GSEABase)
library(reshape2)
library(gplots)
library(viridis)
library(topGO)
```

**read in and format uniprot data**
```{r}
#read in uniprot mapping
uniprot <- read.csv("/Volumes/web/metacarcinus/Cgigas/all_giga-uniprot-blastP-out.nopipe.annotations.tab", sep ="\t", header = FALSE, stringsAsFactors = FALSE)
#rename uniprot columns
colnames(uniprot) <- c("protein_ID","Entry", "Entry_name", "perc_ident_match", "align_len", "num_mismatch", "num_gaps","querStart", "querEnd", "subjStart", "subjEnd", "evalue", "bitscore","Entry.1","Entry_name.1", "Protein_names", "Gene_names", "Organism", "Protein_length","Pathway", "GO_bp", "GO","GO_IDs", "Protein_fams")
#convert columns that should be numeric to numeric
str(uniprot)
uniprot[,4:13] <- lapply(uniprot[,4:13], as.numeric)
#NAs introduced by coercion
#this is because the entries that are unmappaed have NA values
str(uniprot)

#filter for choyp proteins and for evalue <= 10x10^-10 (unmapped proteins get removed here)
uniprot_filtered <- uniprot[grep("CHOYP",uniprot$protein_ID),]
uniprot_filtered <- uniprot[which(uniprot$evalue <= 1*10^-10),]


```

**read in and format ASCA logNSAF time and temp sig. data**
```{r}
silo39_temp_ASCA <- read.csv("~/Documents/GitHub/OysterSeedProject/analysis/ASCA/ASCA_all_proteins_avgADJNSAF/Silo3_9_log/silo3_9_tempSig_prots.csv", stringsAsFactors = FALSE)
colnames(silo39_temp_ASCA)[2] <- "protein_ID"

```

**read in all proteins detected specific for each comparison to generate GO background 
```{r}
silo39_all_prots <- read.csv("~/Documents/GitHub/OysterSeedProject/analysis/ASCA/ASCA_all_proteins_avgADJNSAF/Silo3_9_log/all_silo39_prots.csv", stringsAsFactors = FALSE)

#rename column to protein_ID
colnames(silo39_all_prots)[1] <- "protein_ID"
#remove pipe in protein IDs
silo39_all_prots$protein_ID <- gsub("\\|","\\.", silo39_all_prots$protein_ID)


```

**Match GO terms to sig protein lists**
```{r}
#Get GO IDs for silo 3 and 9 sig. proteins
silo39_sig_pro_GO <- merge(silo39_temp_ASCA, uniprot_filtered[,c("protein_ID","GO_IDs")], by ="protein_ID")

#count number of proteins with GO terms
nrow(silo39_sig_pro_GO)

#Since GO IDs are listed all in one column, spread them across multiple columns (1 column /term)
silo39_sig_pro_GOid_term <- data.frame()
for (i in 1:nrow(silo39_sig_pro_GO)){
  silo39_sig_pro_GOid_term_row <- data.frame(t(data.frame(strsplit(as.character(silo39_sig_pro_GO$GO_IDs[i]),'; ', fixed = TRUE))))
  silo39_sig_pro_GOid_term <- rbind.fill(silo39_sig_pro_GOid_term,silo39_sig_pro_GOid_term_row)
}

#add protein IDs back to GO IDs
silo39_sig_pro_GOid_term <- cbind(silo39_sig_pro_GO[,"protein_ID"], silo39_sig_pro_GOid_term)
#this results in a table with protein ID listed in one column and each next column contains a GO ID that was listed with the protein in Uniprot DB.
#convert all factors to  characters
silo39_sig_pro_GOid_term <- data.frame(lapply(silo39_sig_pro_GOid_term, as.character), stringsAsFactors = FALSE)
#proteins that don't have GO IDs?

#reshape data so that all GO ID columns are gathered in one column called "GO" 
STACKED_silo39_sig_pro_GOid_term <- tidyr::gather(silo39_sig_pro_GOid_term,"col","GO", 2:ncol(silo39_sig_pro_GOid_term))
#exlude middle column which just contains the string "gene" in each row
STACKED_silo39_sig_pro_GOid_term <- STACKED_silo39_sig_pro_GOid_term[,-2]
#remove duplicate rows
STACKED_silo39_sig_pro_GOid_term <- unique(STACKED_silo39_sig_pro_GOid_term)
colnames(STACKED_silo39_sig_pro_GOid_term)[1] <- "protein_ID"
#remove any rows where GO column has NA value. 
STACKED_silo39_sig_pro_GOid_term <- STACKED_silo39_sig_pro_GOid_term[which(!is.na(STACKED_silo39_sig_pro_GOid_term$GO)),]
#this resulting data frame has two columns "gene" and "GO"
#write.csv(STACKED_sig0.1_pro_GOid_term, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/SameDayFCtoTemp/ChiSq_ASCA_clust/intermediate_files/STACKED_sig0.1_pro_GOid_term.csv", quote = FALSE, row.names = FALSE)
```

**MATCH GO TERMS TO BACKGROUND LIST**
This step takes ~10min
```{r}
#Get GO IDs for silo 3 and 9 ALL. proteins
silo39_ALL_pro_GO <- merge(silo39_all_prots, uniprot_filtered[,c("protein_ID","GO_IDs")], by ="protein_ID")

#count number of proteins with GO terms
nrow(silo39_ALL_pro_GO)

#Since GO IDs are listed all in one column, spread them across multiple columns (1 column /term)
silo39_ALL_pro_GOid_term <- data.frame()
for (i in 1:nrow(silo39_ALL_pro_GO)){
  silo39_ALL_pro_GOid_term_row <- data.frame(t(data.frame(strsplit(as.character(silo39_ALL_pro_GO$GO_IDs[i]),'; ', fixed = TRUE))))
  silo39_ALL_pro_GOid_term <- rbind.fill(silo39_ALL_pro_GOid_term,silo39_ALL_pro_GOid_term_row)
}

#add protein IDs back to GO IDs
silo39_ALL_pro_GOid_term <- cbind(silo39_ALL_pro_GO[,"protein_ID"], silo39_ALL_pro_GOid_term)
#this results in a table with protein ID listed in one column and each next column contains a GO ID that was listed with the protein in Uniprot DB.
#convert all factors to  characters
silo39_ALL_pro_GOid_term <- data.frame(lapply(silo39_ALL_pro_GOid_term, as.character), stringsAsFactors = FALSE)
#proteins that don't have GO IDs?

#reshape data so that all GO ID columns are gathered in one column called "GO" 
STACKED_silo39_ALL_pro_GOid_term <- tidyr::gather(silo39_ALL_pro_GOid_term,"col","GO", 2:ncol(silo39_ALL_pro_GOid_term))
#exlude middle column which just contains the string "gene" in each row
STACKED_silo39_ALL_pro_GOid_term <- STACKED_silo39_ALL_pro_GOid_term[,-2]
#remove duplicate rows
STACKED_silo39_ALL_pro_GOid_term <- unique(STACKED_silo39_ALL_pro_GOid_term)
colnames(STACKED_silo39_ALL_pro_GOid_term)[1] <- "protein_ID"
#remove any rows where GO column has NA value. 
STACKED_silo39_ALL_pro_GOid_term <- STACKED_silo39_ALL_pro_GOid_term[which(!is.na(STACKED_silo39_ALL_pro_GOid_term$GO)),]
#this resulting data frame has two columns "gene" and "GO"
#write.csv(STACKED_ALL0.1_pro_GOid_term, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/SameDayFCtoTemp/ChiSq_ASCA_clust/intermediate_files/STACKED_ALL0.1_pro_GOid_term.csv", quote = FALSE, row.names = FALSE)

```


### TopGO 
```{r}

###this chunk generates p-values for weight01 fisher test like Liew paper (https://advances.sciencemag.org/content/4/6/eaar8028/tab-figures-data#ref-43)
library(topGO)


#background list silo39_ALL_pro_GO
#sig pro list silo39_sig_pro_GO

topgo_bkgd <- silo39_ALL_pro_GO
topgo_bkgd$GO_IDs <- gsub(";",",",topgo_bkgd$GO_IDs)
write.table(topgo_bkgd, "TopGO_bkgd.txt", sep = "\t",quote = FALSE, row.names = FALSE, col.names = FALSE)
geneID2GO_bkgd <- readMappings(file = "TopGO_bkgd.txt")

#to switch between time and temp run line 66 in time and temp functional analysis scripts
topgo_sig <- silo39_sig_pro_GO
topgo_sig$GO_IDs <- gsub(";",",",topgo_sig$GO_IDs)

topgo_sig_1 <- topgo_sig[which(topgo_sig$ClusterID == 1),c("protein_ID", "GO_IDs")]

topgo_sig_2 <- topgo_sig[which(topgo_sig$ClusterID == 2),c("protein_ID", "GO_IDs")]


geneUniverse <- names(geneID2GO_bkgd)

genesOfInterest_1 <- topgo_sig_1
genesOfInterest_1 <- as.character(genesOfInterest_1$protein_ID)

geneList_1 <- factor(as.integer(geneUniverse %in% genesOfInterest_1))
names(geneList_1) <- geneUniverse

myGOdata_1 <- new("topGOdata", description="time_clade1", ontology="BP", allGenes=geneList_1  ,annot = annFUN.gene2GO, gene2GO = geneID2GO_bkgd)

resultFisher_1 <- runTest(myGOdata_1, algorithm="weight01", statistic="fisher") 

allRes_1 <- GenTable(myGOdata_1, weight = resultFisher_1,orderBy = "weight", ranksOf = "classic", topNodes = 50)

#clade 2

genesOfInterest_2 <- topgo_sig_2
genesOfInterest_2 <- as.character(genesOfInterest_2$protein_ID)

geneList_2 <- factor(as.integer(geneUniverse %in% genesOfInterest_2))
names(geneList_2) <- geneUniverse

myGOdata_2 <- new("topGOdata", description="time_clade2", ontology="BP", allGenes=geneList_2,  annot = annFUN.gene2GO, gene2GO = geneID2GO_bkgd)

resultFisher_2 <- runTest(myGOdata_2, algorithm="weight01", statistic="fisher") 

allRes_2 <- GenTable(myGOdata_2, weight = resultFisher_2,orderBy = "weight", ranksOf = "classic", topNodes = 50)

sub_allRes1 <- allRes_1[which(allRes_1$Annotated >=5 & allRes_1$weight <= 0.05),]
sub_allRes2 <- allRes_2[which(allRes_2$Annotated >=5 & allRes_2$weight <= 0.05),]

#bind all result subsets into one data frame
sub_allRes <- rbind(sub_allRes1, sub_allRes2)

sub_allRes <- sub_allRes[,1:2]
sub_allRes <- unique(sub_allRes)

sub_allRes <- merge(sub_allRes, sub_allRes1[,c(1,6)], by = "GO.ID", all = TRUE)
colnames(sub_allRes)[3] <- "clade1"

sub_allRes <- merge(sub_allRes, sub_allRes2[,c(1,6)], by = "GO.ID", all = TRUE)
colnames(sub_allRes)[4] <- "clade2"

write.csv(sub_allRes, "Temp_Clades_SigGO.csv", quote = FALSE, row.names = FALSE)

```

#get GO slims for clade terms
```{r}
library(GSEABase)
#make list of unique GO terms without a protein ID column
GO_clade1 <- sub_allRes[which(!is.na(sub_allRes$clade1)),"GO.ID"]
GO_clade2 <- sub_allRes[which(!is.na(sub_allRes$clade2)),"GO.ID"]


#Use GSEA to generate list of GO Slim BP terms for each clade
#DF will have "term", "GOid", "GOcategory"

#goslims with GSEA
collection_clade1 <- GOCollection(GO_clade1)
collection_clade2 <- GOCollection(GO_clade2)

#I downloaded goslim_generic.obo from http://geneontology.org/docs/go-subset-guide/
#then i moved it to the R library for GSEABase in the extdata folder
fl <- system.file("extdata", "goslim_generic.obo", package="GSEABase")
slim <- getOBOCollection(fl)
slims_clade1 <- data.frame(goSlim(collection_clade1, slim, "BP"))
slims_clade2 <- data.frame(goSlim(collection_clade2, slim, "BP"))


#bind all clade slim terms together
slims <- rbind(slims_clade1, slims_clade2)

slims <- data.frame(unique(slims$Term))
colnames(slims)[1] <- "Term"

slims <- merge(slims, slims_clade1[,c("Term", "Count")], by = "Term", all = TRUE)
colnames(slims)[2] <- "clade1"

slims <- merge(slims, slims_clade2[,c("Term", "Count")], by = "Term", all = TRUE)
colnames(slims)[3] <- "clade2"

#remove rows without any counts, and biological_process row

slims <- slims[which(apply(slims[,-1],1,sum)!= 0 & slims$Term != "biological_process"),]

write.csv(slims, "Temp_Clades_SigGOSlim.csv",quote = F, row.names = F)

slims_m <- slims[,-1]
rownames(slims_m) <- slims$Term
slims_m <- data.matrix(slims_m)
colnames(slims_m) <- gsub("clade","",colnames(slims_m))

#replace truncated terms with full terms
rownames(slims_m) <- gsub("nucleobase-containing compound cata...","nucleobase-containing compound catabolic process", rownames(slims_m))

rownames(slims_m) <- gsub("generation of precursor metabolites...","generation of precursor metabolites and energy", rownames(slims_m))

rownames(slims_m) <- gsub("cytoskeleton-dependent intracellula...","cytoskeleton-dependent intracellular transport", rownames(slims_m))

rownames(slims_m) <- gsub("cellular protein modification proce...","cellular protein modification process", rownames(slims_m))

rownames(slims_m) <- gsub("cellular nitrogen compound metaboli...","cellular nitrogen compound metabolic process", rownames(slims_m))

rownames(slims_m) <- gsub("cellular nitrogen compound metaboli...","cellular nitrogen compound metabolic p", rownames(slims_m))

rownames(slims_m) <- gsub("cellular amino acid metabolic proce...","cellular amino acid metabolic process", rownames(slims_m))

rownames(slims_m) <- gsub("anatomical structure formation invo...","anatomical structure formation involved in morphogenesis", rownames(slims_m))




#library(viridis)
#col = rev(viridis(11))
col = c("#FFFFFFFF","#C2DF23FF","#85D54AFF","#51C56AFF","#2BB07FFF","#1E9B8AFF","#25858EFF","#2D708EFF","#38598CFF","#433E85FF","#482173FF","#440154FF")
breaks <- c(-1,0,1,2,3,4,5,6,7,8,9,10,11)

ColSideColors<- c("#000000","#80FFFF")
pdf(file="GOSlimheatmapTemp.pdf", width=8, height=8)
heatmap.2(slims_m,margins = c(5,35),cexCol = 1, Colv=NA,revC = TRUE,breaks= breaks,col = col,density.info = "none", trace = "none", scale = "none",ColSideColors = ColSideColors)
dev.off()

```




COMMENT OUT TIME OR TEMP IN THIS CHUNK BEFORE RUNNING CODE
**Extract GO IDs for different clades**
NEED TO CHANGE FILE NAMES FOR SAVING DATA
```{r}
#temp clades
silo39_clade1_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_temp_ASCA[which(silo39_temp_ASCA$ClusterID == 1),"protein_ID"]),]

write.csv(silo39_clade1_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_temp_clade1_GO.csv", quote = FALSE, row.names = FALSE)

silo39_clade2_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_temp_ASCA[which(silo39_temp_ASCA$ClusterID == 2),"protein_ID"]),]

write.csv(silo39_clade2_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_temp_clade2_GO.csv", quote = FALSE, row.names = FALSE)


#time clades
silo39_clade1_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_time_ASCA[which(silo39_time_ASCA$ClusterID == 1),"protein_ID"]),]

write.csv(silo39_clade1_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_time_clade1_GO.csv", quote = FALSE, row.names = FALSE)

silo39_clade2_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_time_ASCA[which(silo39_time_ASCA$ClusterID == 2),"protein_ID"]),]

write.csv(silo39_clade2_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_time_clade2_GO.csv", quote = FALSE, row.names = FALSE)

silo39_clade3_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_time_ASCA[which(silo39_time_ASCA$ClusterID == 3),"protein_ID"]),]

write.csv(silo39_clade3_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_time_clade3_GO.csv", quote = FALSE, row.names = FALSE)

silo39_clade4_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_time_ASCA[which(silo39_time_ASCA$ClusterID == 4),"protein_ID"]),]

write.csv(silo39_clade4_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_time_clade4_GO.csv", quote = FALSE, row.names = FALSE)

silo39_clade5_GO <- STACKED_silo39_sig_pro_GOid_term[which(STACKED_silo39_sig_pro_GOid_term$protein_ID %in% silo39_time_ASCA[which(silo39_time_ASCA$ClusterID == 5),"protein_ID"]),]

write.csv(silo39_clade5_GO, "~/Documents/GitHub/OysterSeedProject/analysis/UniprotAnnotations_NetworkAnalysis/ASCA_logNSAFs_FunctionalAnalysis/silo39_time_clade5_GO.csv", quote = FALSE, row.names = FALSE)
```

**TOP GO fisher test style enrichment**
```{r}
#save total number of clade proteins and universe proteins as objects
total_clade1_prots <- length(unique(silo39_clade1_GO$protein_ID))
total_clade2_prots <- length(unique(silo39_clade2_GO$protein_ID))

#COMMENT THESE 3 OUT WHEN RUNNING TEMPERATURE
total_clade3_prots <- length(unique(silo39_clade3_GO$protein_ID))
total_clade4_prots <- length(unique(silo39_clade4_GO$protein_ID))
total_clade5_prots <- length(unique(silo39_clade5_GO$protein_ID))


total_universe_prots <- length(unique(STACKED_silo39_ALL_pro_GOid_term$protein_ID))

#define temp or time
k <- "temp"
n <- "time"

#define GO enrichment pval cutoff
#pval <- 0.01

#loop through each unique GO ID and perform a fisher test (comparing representation of GO ID in clade to its representation in the universe)
for(j in (1)){
  clade_data <- read.csv(paste0("silo39_",n,"_clade",j,"_GO.csv"), stringsAsFactors = FALSE)
  uniq_clade_data <- unique(clade_data$GO)

  #make table with unique GO ID and # proteins with GO ID
  GO_enrich <- data.frame(matrix(0,nrow=length(uniq_clade_data),ncol=3))
  colnames(GO_enrich) <- c("GO","p.value","p.adj")
  for(i in (1:length(uniq_clade_data))){
    num_sig_prots <- nrow(clade_data[grep(uniq_clade_data[[i]],clade_data$GO),])
    num_prots <- nrow(STACKED_silo39_ALL_pro_GOid_term[grep(uniq_clade_data[[i]],STACKED_silo39_ALL_pro_GOid_term$GO),])
    cont_table <- matrix(c(num_sig_prots,num_prots,total_clade1_prots,total_universe_prots),nrow=2,dimnames = list(c("sig prots","prots"),c("total sig prots","prot univ")))
    test <- fisher.test(cont_table) 
    GO_enrich$GO[i] <- uniq_clade_data[[i]]
    GO_enrich$p.value[i] <- test$p.value
    GO_enrich$p.adj[i] <- p.adjust(test$p.value, method = "fdr", n = length(uniq_clade_data))
  }
  #GO_enrich_0.1 <- data.frame(GO_enrich[which(GO_enrich$p.value<=0.1),c("GO","p.value","p.adj")])
  #print(nrow(GO_enrich_0.1))
  #write.csv(GO_enrich_0.05,paste0("GO_enrich_0.05_silo39_temp_clade",j,".csv"),quote = FALSE, row.names = FALSE)
}


#for time clades 1-3, don't do enrichment because not enough GO terms
```

```{r}
for(j in (2)){
  clade_data <- read.csv(paste0("silo39_temp_clade",j,"_GO.csv"), stringsAsFactors = FALSE)
  uniq_clade_data <- unique(clade_data$GO)

  #make table with unique GO ID and # proteins with GO ID
  GO_enrich <- data.frame(matrix(0,nrow=length(uniq_clade_data),ncol=3))
  colnames(GO_enrich) <- c("GO","p.value","p.adj")
  for(i in (1:length(uniq_clade_data))){
    num_sig_prots <- nrow(clade_data[grep(uniq_clade_data[[i]],clade_data$GO),])
    num_prots <- nrow(STACKED_silo39_ALL_pro_GOid_term[grep(uniq_clade_data[[i]],STACKED_silo39_ALL_pro_GOid_term$GO),])
    cont_table <- matrix(c(num_sig_prots,num_prots,total_clade1_prots,total_universe_prots),nrow=2,dimnames = list(c("sig prots","prots"),c("total sig prots","prot univ")))
    test <- fisher.test(cont_table) 
    GO_enrich$GO[i] <- uniq_clade_data[[i]]
    GO_enrich$p.value[i] <- test$p.value
    GO_enrich$p.adj[i] <- p.adjust(test$p.value, method = "fdr", n = length(uniq_clade_data))
  }
  GO_enrich_0.01 <- data.frame(GO_enrich[which(GO_enrich$p.value<=0.01),c("GO","p.value","p.adj")])
  write.csv(GO_enrich_0.01,paste0("GO_enrich_0.01_silo39_temp_clade",j,".csv"),quote = FALSE, row.names = FALSE)
}
```



**GO SEMSIM OF ENRICHED GENES**
```{r}
#load GO data and GO info from OntologyIndex package
data(go)
data(GO_IC)

for(j in (1)){
  GO_enrich_0.05 <- read.csv(paste0("GO_enrich_0.05_silo39_temp_clade",j,".csv"), stringsAsFactors = FALSE)
 #create a list of character vectors called terms from enriched GO IDs
  terms <- as.list(GO_enrich_0.05$GO)
  #Get GO info in ontologyX database (GO.obo) for terms in "terms" list
  GO_IC_data <- get_term_info_content(go, term_sets = as.vector(GO_enrich_0.05$GO))
  #Subset terms to match 
  terms <- terms[terms %in% names(GO_IC_data)]
  #create a semantic similarity matrix with enriched GO IDs
  sim_matrix <- get_sim_grid(ontology=go,information_content=GO_IC_data,term_sets=terms)
  #add row and column names that are the GO IDs
  rownames(sim_matrix) <- unlist(terms)
  colnames(sim_matrix) <- unlist(terms)
  
  #save sim matrix
  write.csv(sim_matrix,paste0("enrichGOsemsim_matrix_",j,".csv"), quote = FALSE)
  
  #plot heat map of simantic similarities
  pdf(file=paste0("GOsimsem_heatmap_silo39_temp_clade",j,".pdf"), width=10, height=8)
  heatmap3(sim_matrix, scale = "none")
  dev.off()
}

for(j in (2)){
  GO_enrich_0.01 <- read.csv(paste0("GO_enrich_0.05_silo39_temp_clade",j,".csv"), stringsAsFactors = FALSE)
 #create a list of character vectors called terms from enriched GO IDs
  terms <- as.list(GO_enrich_0.01$GO)
  #Get GO info in ontologyX database (GO.obo) for terms in "terms" list
  GO_IC_data <- get_term_info_content(go, term_sets = as.vector(GO_enrich_0.01$GO))
  #Subset terms to match 
  terms <- terms[terms %in% names(GO_IC_data)]
  #create a semantic similarity matrix with enriched GO IDs
  sim_matrix <- get_sim_grid(ontology=go,information_content=GO_IC_data,term_sets=terms)
  #add row and column names that are the GO IDs
  rownames(sim_matrix) <- unlist(terms)
  colnames(sim_matrix) <- unlist(terms)
  
  #save sim matrix
  write.csv(sim_matrix,paste0("enrichGOsemsim_matrix_",j,".csv"), quote = FALSE)
  
  #plot heat map of simantic similarities
  pdf(file=paste0("GOsimsem_heatmap_silo39_temp_clade",j,".pdf"), width=10, height=8)
  heatmap3(sim_matrix, scale = "none")
  dev.off()
}
```

**Finding clusters in heatmap**
Dendrogram should be inspected manually with heatmap to determine where the tree should be cut to get the appropriate number of clusters
```{r}
#find clusters in heatmap

#define clade
j=1
#read in matrix data
sim_matrix <- read.csv(paste0("enrichGOsemsim_matrix_",j,".csv"), stringsAsFactors = FALSE)

#format matrix data for as.dist
sim_matrix <- data.matrix(sim_matrix)
sim_matrix <- sim_matrix[,-1]
colnames(sim_matrix) <- gsub("\\.",":", colnames(sim_matrix))
rownames(sim_matrix) <- colnames(sim_matrix)
#plot dendrogram  
hm <- as.dist(1-cor(t(sim_matrix), use="pa"))
hm2 <- hclust(hm, method = 'complete')
plot(hm2)

cut <- 0.3
abline(h=cut, col = "red")

############################################################
#make a list of proteins with cluster IDs based on where the tree is cut

#for complete clustering
mycl <- cutree(hm2,h=cut)

#assign colors to cluster IDs
clusterCols <- colorRamps::primary.colors(length(unique(mycl)))
myClusterSideBar <- clusterCols[mycl]

#replot and save heatmap with clades
pdf(file=paste0("GOsimsem_heatmap_silo39_temp_clade",j,".pdf"), width=10, height=8)
heatmap3(sim_matrix,cexRow = 0.5, cexCol = 0.5, RowSideColors=myClusterSideBar,RowAxisColors=1,hclustfun=hclust, distfun = function(x) as.dist(1 - cor(t(x), use = "pa")), method = "complete", scale = "none")
dev.off()

#get color name
clusterColor <- lapply(myClusterSideBar, color.id)
clusterColor <- lapply(clusterColor, `[[`,1)
clusterColor <- data.frame(unlist(clusterColor), stringsAsFactors = FALSE)

#merge cluster color with GO ID and cluster number
foo <- cbind(data.frame(mycl), clusterColor)
foo$GO <- rownames(foo)
colnames(foo) <- c("Clust_Num","Clust_Color","GO")

#set values < 0.5 or 1 in sim_matrix to 0, convert to dataframe and add GO IDs as column
sim_matrix1 <- sim_matrix
sim_matrix1[sim_matrix1<0.5] <- 0
sim_matrix1[sim_matrix1==1] <- 0

sim_matrix1 <- data.frame(sim_matrix1)
sim_matrix1$GO <- row.names(sim_matrix1)

#merge clade info with sim_matrix
sim_matrix_clade <- merge(foo,data.frame(sim_matrix1), by = "GO")

#sum the semantic similarity scores for each GO ID
sim_matrix_clade$sumsim <- apply(sim_matrix_clade[,5:ncol(sim_matrix_clade)],1,sum)
#exclude any terms that summed to 0; this happens because many terms are set to 0 in the step above and remove individual GO columns now that we have the sum for each term
sim_matrix_clade <- sim_matrix_clade[which(sim_matrix_clade$sumsim!=0),c(1:3,ncol(sim_matrix_clade))]

#make a data frame with the cluster color and the semantic similarity sum of all term sums
color_sums <- aggregate(sim_matrix_clade$sumsim, by=list(Category=sim_matrix_clade$Clust_Color), FUN=sum)
#rename columns
colnames(color_sums) <- c("Clust_Color","semsimsum")
#add color sum to the abbreviated sim matrix
sim_matrix_clade_sums <- merge(sim_matrix_clade,color_sums, by = "Clust_Color")
#Get the full GO term info for each GO ID
for(i in 1:nrow(sim_matrix_clade_sums)){
  sim_matrix_clade_sums$term[i] <- go$name[[sim_matrix_clade_sums$GO[i]]]
}

#remove commas from GO terms so it wont interfere with saving data as .csv
sim_matrix_clade_sums$term <- gsub(",",";", sim_matrix_clade_sums$term)

#read in GO slim info to add to sim_matrix_clade_sums data frame
srlabslim <- read.csv("~/Documents/GitHub/OysterSeedProject/raw_data/background/GOSlim_terms.csv", stringsAsFactors = FALSE)
colnames(srlabslim)[1] <- "GO"

#some GO terms have muliple GO slims so for these, combine GO slims into one line and separate them with a ;
agg_df <- merge(sim_matrix_clade_sums,srlabslim[,c("GO","GOSlim_bin")],by = "GO",all.x = TRUE)
agg_df <- aggregate(GOSlim_bin~GO, agg_df, paste, collapse = ";")
#merge GOslim data with sim_matrix_clade_sums data frame
sim_matrix_clade_sums <-merge(sim_matrix_clade_sums,agg_df, by = "GO", all.x = TRUE)
#add p.value info to data frame
GO_enrich_0.05 <- read.csv(paste0("GO_enrich_0.05_silo39_clade",j,".csv"), stringsAsFactors = FALSE)
sim_matrix_clade_sums <- merge(sim_matrix_clade_sums,GO_enrich_0.05, by = "GO", all.x = TRUE)
#order data by semantic similarity sum
sim_matrix_clade_sums <- sim_matrix_clade_sums[order(sim_matrix_clade_sums$semsimsum,decreasing = TRUE),]


write.csv(sim_matrix_clade_sums,paste0("silo39_temp_clade",j,"_GOenrich_clust.csv"), quote = FALSE, row.names = FALSE)

###GO terms and pvalues are then uploaded into revigo with 0.5 (small setting)

```