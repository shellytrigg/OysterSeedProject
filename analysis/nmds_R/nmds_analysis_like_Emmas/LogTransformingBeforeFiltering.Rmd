---
title: "Log transforming before SD and percent error filtering"
author: "Shelly Trigg"
date: "1/16/2019"
output:rmarkdown::github_document
---

Load packages
```{r}
library(vegan)
library(ggplot2)
library(dplyr)
library(gtools)
library(MLmetrics)
```

Read in data
```{r}
silo3and9_nozerovar <- read.csv("~/Documents/GitHub/OysterSeedProject/analysis/nmds_R/silo3and9_nozerovals.csv", stringsAsFactors = FALSE)
silo3and9_meta <- silo3and9_nozerovar[,1:3]
colnames(silo3and9_meta) <- c("Sample.ID", "day", "temp")
str(silo3and9_meta)
silo3and9_meta$day <- factor(silo3and9_meta$day, levels = unique(silo3and9_meta$day))
silo3and9_meta$temp <- factor(silo3and9_meta$temp, levels = unique(silo3and9_meta$temp))
str(silo3and9_meta)
silo3and9_nozerovar <- silo3and9_nozerovar[,-c(1:3)]
rownames(silo3and9_nozerovar) <- silo3and9_meta$Sample.ID

silo3and9_nozerovar_log <- log(silo3and9_nozerovar,2)
```

Check if any pair of replicates have protein NSAF values that show > 20% error AND an SD > 5; those are the potentially unrealiable proteins
```{r}
#create an empty data frame
df_log <- data.frame()
#loop through the data and calculate the standard deviation between replicates for each protein
#this calculates the SD for 
for (i in seq(1,nrow(silo3and9_nozerovar_log),2)){
  #this calculates the SD for each odd number row and the row following it
  df_log_row <- apply(silo3and9_nozerovar_log[c(i,i+1),],2,sd)
  #this sequencially combines rows of data together after the SD is generated
  df_log <- rbind(df_log, df_log_row)
}
#add column names to SD data
colnames(df_log) <- colnames(silo3and9_nozerovar_log)
rownames(df_log) <- rownames(silo3and9_nozerovar_log[-grep("A",rownames(silo3and9_nozerovar_log)),])

#create a new SD data frame to parse out proteins with SD > 5
df_log_SD5 <- df
#convert SD values > 5 to NA
df_log_SD5[df_log_SD5 > 5] <- NA
#transpose the data frame so that proteins are column names and sample number is row names
df_log_SD5 <- t.data.frame(df_log_SD5)
#parse out rows (proteins) with SD > 5 in any sample
df_log_SD5 <- df_log_SD5[rowSums(is.na(df_log_SD5)) > 0,]

#create an empty data frame
df_log_err <- data.frame()
#loop through data and calculate percent error between replicates for each protein
#this goes through each odd numbered row(i), and looks at each protein (j) in each odd row then computes the percent error by comparing it to the protein (j) in the odd row + 1 (i + 1). The computed percent error is filled into the empty data frame using the same coordinates as its origin. 
for (i in seq(1,nrow(silo3and9_nozerovar_log),2)){
  for(j in 1:ncol(silo3and9_nozerovar_log)){
    true <- silo3and9_nozerovar_log[i,j]
    pred <- silo3and9_nozerovar_log[i+1, j]
    df_log_err[i,j] <- abs(pred-true)/true *100
  }  
}    

#remove empty rows in data frame
df_log_err <- df_log_err[c(seq(1,nrow(silo3and9_nozerovar_log),2)),]  
#add column names (protein names) back
colnames(df_log_err) <- colnames(silo3and9_nozerovar_log)
#add row names (sample names) back
rownames(df_log_err) <- rownames(silo3and9_nozerovar_log[-grep("A",rownames(silo3and9_nozerovar_log)),])

#create a new data frame to subset from
df_log_err_20 <- df_log_err
#convert values > than 20% error in data frame to NAs
df_log_err_20[df_log_err_20 > 20] <- NA
#transform data frame so rows are protein names and columns are sample names
df_log_err_20 <- t.data.frame(df_log_err_20)
#extract proteins that contain NA values (https://stackoverflow.com/questions/7980622/subset-of-rows-containing-na-missing-values-in-a-chosen-column-of-a-data-frame)
df_log_err_20  <- df_log_err_20[rowSums(is.na(df_log_err_20)) > 0,]

#create a list of proteins with any replicate SD > 5 or %error > 20
df_log_err20_SD5 <- rownames(df_log_err_20[which(rownames(df_log_err_20) %in% rownames(df_log_SD5)),])

#try removing these and seeing if PCA improves
silo3and9_nozerovar_log_err20_SD5 <- silo3and9_nozerovar_log[,-c(which(colnames(silo3and9_nozerovar_log) %in% df_log_err20_SD5))]
#chech it worked
ncol(silo3and9_nozerovar_log) - ncol(silo3and9_nozerovar_log_err20_SD5)
length(df_log_err20_SD5)
```

Plot PCA with inconsistent proteins removed
```{r}
pca_log_cut <- prcomp(silo3and9_nozerovar_log_err20_SD5, center = T, scale = T)
pca_log_cut_meta <- cbind(silo3and9_meta$day, silo3and9_meta$temp,data.frame(pca_cut$x))
colnames(pca_log_cut_meta)[1:2] <- c("day","temp")
ggplot(pca_log_cut_meta, aes(PC1, PC2)) + geom_point(aes(col = day, shape = temp)) + theme_bw() + ggtitle("PCA of log ADJNSAF values where zeros were replaced with 0.1 and inconsistently detected proteins removed") + theme(plot.title = element_text(size = 7, face = "bold"))
```

```{r}
#make data frame of NMDS scores

nmds.silo3and9_nozerovar_err20_SD5_log <- metaMDS(silo3and9_nozerovar_log_err20_SD5, distance = 'euclidean', k = 2, trymax = 3000, autotransform = FALSE)

nmds.silo3and9_nozerovar_err20_SD5_log.scores <- cbind(silo3and9_meta$day, silo3and9_meta$temp,data.frame(scores(nmds.silo3and9_nozerovar_err20_SD5_log)))
colnames(nmds.silo3and9_nozerovar_err20_SD5_log.scores)[1:2] <- c("day","temp")
ggplot(nmds.silo3and9_nozerovar_err20_SD5_log.scores, aes(NMDS1, NMDS2)) + geom_point(aes(col = day, shape = temp)) + theme_bw() + ggtitle("NMDS of log ADJNSAF values with zeros replaced with 0.1 and inconsistently detected proteins removed") + theme(plot.title = element_text(size = 7, face = "bold"))
```

Average NSAF values 
```{r}
df_avg <- data.frame()
#loop through the data and calculate the mean between replicates for each protein
for (i in seq(1,nrow(silo3and9_nozerovar_err20_SD5),2)){
  #this calculates the SD for each odd number row and the row following it
  df_avg_row <- apply(silo3and9_nozerovar_err20_SD5[c(i,i+1),],2,mean)
  #this sequencially combines rows of data together after the SD is generated
  df_avg <- rbind(df_avg, df_avg_row)
}
#add column names to SD data
colnames(df_avg) <- colnames(silo3and9_nozerovar_err20_SD5)
df_avg$Sample.ID <- rownames(silo3and9_nozerovar_err20_SD5[-grep("A",rownames(silo3and9_nozerovar_err20_SD5)),])

```
export filtered protein data set
```{r,echo=FALSE, eval=FALSE}
new_data <- merge(silo3and9_meta,df_avg, by = "Sample.ID")
new_data <- new_data[order(new_data$day, new_data$temp),]
write.csv(new_data, "~/Documents/GitHub/OysterSeedProject/analysis/nmds_R/silo3and9_nozerovals_noincnstprot.csv", row.names = FALSE, quote = FALSE)
```